{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. The code such that it uses GPU and\n",
        "2. The architecture to C1C2C3C40 (No MaxPooling, but 3 3x3 layers with stride of 2 instead) \n",
        "3. Total RF must be more than 44\n",
        "4. One of the layers must use Depthwise Separable Convolution\n",
        "5. One of the layers must use Dilated Convolution\n",
        "\n",
        "**Note** -: use GAP (compulsory):- add FC after GAP to target #of classes (optional)\n",
        "\n",
        "use albumentation library and apply:\n",
        "\n",
        "a. Horizontal flip\n",
        "\n",
        "b. ShiftScaleRotate\n",
        "\n",
        "c. CoarseDropout (max_holes = 1, max_height=16px, max_width=1, min_holes = 1, min_height=16px, min_width=16px, fill_value=(mean of your dataset), mask_fill_value = None)\n",
        "\n",
        "\n",
        "d. Achieve 85% accuracy, as many epochs as you want. Total Params to be less than 200k."
      ],
      "metadata": {
        "id": "eVcnzz81SOcx"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO-7t1Y7-hV4"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kH16rnZ7wt_"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import numpy as np "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Cifar10SearchDataset(torchvision.datasets.CIFAR10):\n",
        "    def __init__(self, root=\"~/data/cifar10\", train=True, download=True, transform=None):\n",
        "\n",
        "        super().__init__(root=root, train=train, download=download, transform=transform)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image, label = self.data[index], self.targets[index]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "        return image, label\n",
        "\n",
        "class args():\n",
        "\n",
        "    def __init__(self,device = 'cpu' ,use_cuda = False) -> None:\n",
        "\n",
        "        self.batch_size = 128\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.use_cuda = use_cuda\n",
        "\n",
        "        self.kwargs = {'num_workers': 1, 'pin_memory': True} if self.use_cuda else {}"
      ],
      "metadata": {
        "id": "_ZDdaj3HIEgp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky3f_Odl-7um"
      },
      "source": [
        "## Data Transformations\n",
        "\n",
        "We first start with defining our data transformations. We need to think what our data is and how can we augment it to correct represent images which it might not see otherwise. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = A.Compose(\n",
        "    [\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "            A.ShiftScaleRotate(\n",
        "               shift_limit=0.0625, scale_limit=0.1, \n",
        "                rotate_limit=45, interpolation=1, \n",
        "                border_mode=4, p=0.2\n",
        "            ),\n",
        "            A.CoarseDropout(\n",
        "                max_holes=2, max_height=8, \n",
        "                max_width=8, p=0.1\n",
        "            ),\n",
        "        A.Normalize(\n",
        "            mean = (0.491, 0.482, 0.447),\n",
        "            std = (0.247, 0.243, 0.262)           \n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")\n",
        "\n",
        "test_transforms = A.Compose(\n",
        "    [\n",
        "        A.Normalize(\n",
        "            mean = (0.491, 0.482, 0.447),\n",
        "            std = (0.247, 0.243, 0.262)\n",
        "        ),\n",
        "        ToTensorV2()\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "fwnoQXKgPfAq"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQciFYo2B1mO"
      },
      "source": [
        "# Dataset and Creating Train/Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4A84rlfDA23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d34b6278-a81c-4a2a-be8f-94b508a90ba7"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "# CUDA?\n",
        "cuda = torch.cuda.is_available()\n",
        "print(\"CUDA Available?\", cuda)\n",
        "\n",
        "# For reproducibility\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "trainset = Cifar10SearchDataset(root='./data', train=True, download=True, transform=train_transforms)\n",
        "\n",
        "testset = Cifar10SearchDataset(root='./data', train=False,download=True, transform=test_transforms)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available? True\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgldp_3-Dn0c"
      },
      "source": [
        "# Dataloader Arguments & Test/Train Dataloaders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8OLDR79DrHG"
      },
      "source": [
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=args().batch_size, shuffle=True, **args().kwargs)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=args().batch_size, shuffle=False, **args().kwargs)     \n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat','deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Model"
      ],
      "metadata": {
        "id": "-nvWoioYrcDw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import model"
      ],
      "metadata": {
        "id": "E3dMl9xcR7R2"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-vp8X9LCWo"
      },
      "source": [
        "#Creating instance of all the 3 Models by passing Normalization Type as a Parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skB97zIJQQe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01ee44d2-62fd-48a0-a0f9-623b5089eab8"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "#import model\n",
        "#from model import Net\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "print(device)\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(3, 32, 32))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "cuda\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 30, 30]             280\n",
            "       BatchNorm2d-2           [-1, 10, 30, 30]              20\n",
            "              ReLU-3           [-1, 10, 30, 30]               0\n",
            "            Conv2d-4           [-1, 32, 28, 28]           2,912\n",
            "       BatchNorm2d-5           [-1, 32, 28, 28]              64\n",
            "              ReLU-6           [-1, 32, 28, 28]               0\n",
            "            Conv2d-7           [-1, 64, 26, 26]          18,496\n",
            "       BatchNorm2d-8           [-1, 64, 26, 26]             128\n",
            "              ReLU-9           [-1, 64, 26, 26]               0\n",
            "           Conv2d-10           [-1, 64, 22, 22]          36,928\n",
            "      BatchNorm2d-11           [-1, 64, 22, 22]             128\n",
            "             ReLU-12           [-1, 64, 22, 22]               0\n",
            "          Dropout-13           [-1, 64, 22, 22]               0\n",
            "           Conv2d-14           [-1, 32, 22, 22]          18,464\n",
            "      BatchNorm2d-15           [-1, 32, 22, 22]              64\n",
            "             ReLU-16           [-1, 32, 22, 22]               0\n",
            "           Conv2d-17           [-1, 16, 22, 22]           4,624\n",
            "      BatchNorm2d-18           [-1, 16, 22, 22]              32\n",
            "             ReLU-19           [-1, 16, 22, 22]               0\n",
            "           Conv2d-20           [-1, 16, 18, 18]           2,320\n",
            "      BatchNorm2d-21           [-1, 16, 18, 18]              32\n",
            "             ReLU-22           [-1, 16, 18, 18]               0\n",
            "          Dropout-23           [-1, 16, 18, 18]               0\n",
            "           Conv2d-24           [-1, 32, 18, 18]           4,640\n",
            "      BatchNorm2d-25           [-1, 32, 18, 18]              64\n",
            "             ReLU-26           [-1, 32, 18, 18]               0\n",
            "           Conv2d-27           [-1, 64, 18, 18]          18,496\n",
            "      BatchNorm2d-28           [-1, 64, 18, 18]             128\n",
            "             ReLU-29           [-1, 64, 18, 18]               0\n",
            "           Conv2d-30          [-1, 128, 14, 14]          73,856\n",
            "      BatchNorm2d-31          [-1, 128, 14, 14]             256\n",
            "             ReLU-32          [-1, 128, 14, 14]               0\n",
            "          Dropout-33          [-1, 128, 14, 14]               0\n",
            "           Conv2d-34           [-1, 64, 12, 12]           1,216\n",
            "      BatchNorm2d-35           [-1, 64, 12, 12]             128\n",
            "             ReLU-36           [-1, 64, 12, 12]               0\n",
            "           Conv2d-37           [-1, 10, 12, 12]             650\n",
            "      BatchNorm2d-38           [-1, 10, 12, 12]              20\n",
            "             ReLU-39           [-1, 10, 12, 12]               0\n",
            "        AvgPool2d-40             [-1, 10, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 183,946\n",
            "Trainable params: 183,946\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 5.13\n",
            "Params size (MB): 0.70\n",
            "Estimated Total Size (MB): 5.84\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__x_SbrL7z3"
      },
      "source": [
        "# Training \n",
        "Let's write train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbkF2nN_LYIb"
      },
      "source": [
        "def train(model, device, train_loader, optimizer, epoch, L1):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        if L1:\n",
        "          L1_loss = nn.L1Loss(size_average=None, reduce=None, reduction='mean')\n",
        "          reg_loss = 0 \n",
        "          for param in model.parameters():\n",
        "            zero_vector = torch.rand_like(param) * 0\n",
        "            reg_loss += L1_loss(param,zero_vector)\n",
        "          loss += .001 * reg_loss\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    print(f'Train set: Average loss: {loss.item():.4f}, Accuracy: {100. * correct/len(train_loader.dataset):.2f}')\n",
        "    train_loss = epoch_loss / len(train_loader)\n",
        "    train_acc=100.*correct/len(train_loader.dataset)\n",
        "    return train_loss, train_acc"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing\n",
        "Let's write testing function"
      ],
      "metadata": {
        "id": "EDvxsAYTQDrh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    test_pred = torch.LongTensor()\n",
        "    target_pred = torch.LongTensor()\n",
        "    target_data = torch.LongTensor()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            pred_cpu = output.cpu().data.max(dim=1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            test_pred = torch.cat((test_pred, pred_cpu), dim=0)\n",
        "            target_pred = torch.cat((target_pred, target.cpu()), dim=0)\n",
        "            target_data = torch.cat((target_data, data.cpu()), dim=0)\n",
        "\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_acc = 100.*correct/len(test_loader.dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.3f}, Accuracy: {100. * correct/len(test_loader.dataset):.2f}')\n",
        "    return test_loss, test_acc, test_pred, target_pred, target_data"
      ],
      "metadata": {
        "id": "I608AEtkxgQy"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drokW8wWODKq"
      },
      "source": [
        "# A main function calling test and train functions\n",
        "\n",
        "#Input Params\n",
        "\n",
        "*   EPOCHS\n",
        "*   model\n",
        "*   device\n",
        "*   train_loader\n",
        "*   test_loader\n",
        "*   optimizer\n",
        "*   L1 (Lasso Regression is true or false)\n",
        "\n",
        "#OutPut Params\n",
        "* train_loss_values\n",
        "* test_loss_values\n",
        "* train_acc_values\n",
        "* test_acc_values\n",
        "* test_pred\n",
        "* target_pred\n",
        "* target_data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCFxeAKOB53"
      },
      "source": [
        "def main(EPOCHS, model, device, train_loader, test_loader, optimizer, L1):\n",
        "  train_loss_values = []\n",
        "  test_loss_values = []\n",
        "  train_acc_values = []\n",
        "  test_acc_values = []\n",
        "\n",
        "  for epoch in range(EPOCHS):\n",
        "      print('\\nEpoch {} : '.format(epoch))\n",
        "      # train the model\n",
        "      train_loss, train_acc = train(model, device, train_loader, optimizer, epoch, L1)\n",
        "      test_loss, test_acc, test_pred, target_pred, target_data  = test(model, device, test_loader)\n",
        "\n",
        "      train_loss_values.append(train_loss)\n",
        "      test_loss_values.append(test_loss)\n",
        "\n",
        "      train_acc_values.append(train_acc)\n",
        "      test_acc_values.append(test_acc)\n",
        "\n",
        "  return train_loss_values, test_loss_values, train_acc_values, test_acc_values, test_pred, target_pred, target_data"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calling the Model with 75 Epochs"
      ],
      "metadata": {
        "id": "dvT-IxCJpX3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 75\n",
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.04, momentum=0.9)\n",
        "l1reg = False\n",
        "train_loss, test_loss, train_acc, test_acc , test_pred, target_pred, target_data = main(EPOCHS, model, device, trainloader, testloader, optimizer, l1reg)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkCZw25xpcei",
        "outputId": "b8973ce7-9f3d-4559-dd6f-cb5fdaf7358b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 : \n",
            "Train set: Average loss: 1.6668, Accuracy: 36.99\n",
            "\n",
            "Test set: Average loss: 1.439, Accuracy: 47.88\n",
            "\n",
            "Epoch 1 : \n",
            "Train set: Average loss: 1.1627, Accuracy: 50.12\n",
            "\n",
            "Test set: Average loss: 1.317, Accuracy: 53.22\n",
            "\n",
            "Epoch 2 : \n",
            "Train set: Average loss: 1.3828, Accuracy: 57.03\n",
            "\n",
            "Test set: Average loss: 1.080, Accuracy: 61.90\n",
            "\n",
            "Epoch 3 : \n",
            "Train set: Average loss: 1.0919, Accuracy: 61.69\n",
            "\n",
            "Test set: Average loss: 1.049, Accuracy: 63.08\n",
            "\n",
            "Epoch 4 : \n",
            "Train set: Average loss: 0.8020, Accuracy: 64.39\n",
            "\n",
            "Test set: Average loss: 0.951, Accuracy: 66.01\n",
            "\n",
            "Epoch 5 : \n",
            "Train set: Average loss: 0.9759, Accuracy: 66.70\n",
            "\n",
            "Test set: Average loss: 0.868, Accuracy: 70.25\n",
            "\n",
            "Epoch 6 : \n",
            "Train set: Average loss: 0.9657, Accuracy: 68.48\n",
            "\n",
            "Test set: Average loss: 0.838, Accuracy: 71.01\n",
            "\n",
            "Epoch 7 : \n",
            "Train set: Average loss: 0.8676, Accuracy: 70.01\n",
            "\n",
            "Test set: Average loss: 0.787, Accuracy: 72.48\n",
            "\n",
            "Epoch 8 : \n",
            "Train set: Average loss: 0.7883, Accuracy: 71.41\n",
            "\n",
            "Test set: Average loss: 0.805, Accuracy: 71.62\n",
            "\n",
            "Epoch 9 : \n",
            "Train set: Average loss: 0.7708, Accuracy: 72.57\n",
            "\n",
            "Test set: Average loss: 0.783, Accuracy: 73.15\n",
            "\n",
            "Epoch 10 : \n",
            "Train set: Average loss: 0.8835, Accuracy: 73.38\n",
            "\n",
            "Test set: Average loss: 0.728, Accuracy: 74.80\n",
            "\n",
            "Epoch 11 : \n",
            "Train set: Average loss: 0.8318, Accuracy: 74.13\n",
            "\n",
            "Test set: Average loss: 0.705, Accuracy: 75.29\n",
            "\n",
            "Epoch 12 : \n",
            "Train set: Average loss: 0.7087, Accuracy: 75.12\n",
            "\n",
            "Test set: Average loss: 0.689, Accuracy: 76.23\n",
            "\n",
            "Epoch 13 : \n",
            "Train set: Average loss: 0.7035, Accuracy: 75.69\n",
            "\n",
            "Test set: Average loss: 0.682, Accuracy: 76.90\n",
            "\n",
            "Epoch 14 : \n",
            "Train set: Average loss: 0.8263, Accuracy: 76.49\n",
            "\n",
            "Test set: Average loss: 0.663, Accuracy: 76.94\n",
            "\n",
            "Epoch 15 : \n",
            "Train set: Average loss: 0.7274, Accuracy: 77.12\n",
            "\n",
            "Test set: Average loss: 0.634, Accuracy: 78.30\n",
            "\n",
            "Epoch 16 : \n",
            "Train set: Average loss: 0.6504, Accuracy: 77.70\n",
            "\n",
            "Test set: Average loss: 0.634, Accuracy: 78.29\n",
            "\n",
            "Epoch 17 : \n",
            "Train set: Average loss: 0.8669, Accuracy: 77.92\n",
            "\n",
            "Test set: Average loss: 0.690, Accuracy: 76.23\n",
            "\n",
            "Epoch 18 : \n",
            "Train set: Average loss: 0.6749, Accuracy: 78.24\n",
            "\n",
            "Test set: Average loss: 0.617, Accuracy: 78.79\n",
            "\n",
            "Epoch 19 : \n",
            "Train set: Average loss: 0.6946, Accuracy: 78.74\n",
            "\n",
            "Test set: Average loss: 0.589, Accuracy: 79.73\n",
            "\n",
            "Epoch 20 : \n",
            "Train set: Average loss: 0.5683, Accuracy: 79.08\n",
            "\n",
            "Test set: Average loss: 0.592, Accuracy: 79.68\n",
            "\n",
            "Epoch 21 : \n",
            "Train set: Average loss: 0.8007, Accuracy: 79.41\n",
            "\n",
            "Test set: Average loss: 0.606, Accuracy: 79.38\n",
            "\n",
            "Epoch 22 : \n",
            "Train set: Average loss: 0.5283, Accuracy: 80.05\n",
            "\n",
            "Test set: Average loss: 0.604, Accuracy: 79.59\n",
            "\n",
            "Epoch 23 : \n",
            "Train set: Average loss: 0.4808, Accuracy: 80.19\n",
            "\n",
            "Test set: Average loss: 0.576, Accuracy: 80.44\n",
            "\n",
            "Epoch 24 : \n",
            "Train set: Average loss: 0.6472, Accuracy: 80.47\n",
            "\n",
            "Test set: Average loss: 0.577, Accuracy: 80.57\n",
            "\n",
            "Epoch 25 : \n",
            "Train set: Average loss: 0.6432, Accuracy: 80.69\n",
            "\n",
            "Test set: Average loss: 0.568, Accuracy: 81.08\n",
            "\n",
            "Epoch 26 : \n",
            "Train set: Average loss: 0.6150, Accuracy: 81.10\n",
            "\n",
            "Test set: Average loss: 0.623, Accuracy: 79.20\n",
            "\n",
            "Epoch 27 : \n",
            "Train set: Average loss: 0.5888, Accuracy: 81.27\n",
            "\n",
            "Test set: Average loss: 0.554, Accuracy: 81.22\n",
            "\n",
            "Epoch 28 : \n",
            "Train set: Average loss: 0.4177, Accuracy: 81.55\n",
            "\n",
            "Test set: Average loss: 0.590, Accuracy: 80.15\n",
            "\n",
            "Epoch 29 : \n",
            "Train set: Average loss: 0.6170, Accuracy: 81.84\n",
            "\n",
            "Test set: Average loss: 0.554, Accuracy: 81.25\n",
            "\n",
            "Epoch 30 : \n",
            "Train set: Average loss: 0.7104, Accuracy: 81.82\n",
            "\n",
            "Test set: Average loss: 0.535, Accuracy: 82.16\n",
            "\n",
            "Epoch 31 : \n",
            "Train set: Average loss: 0.7070, Accuracy: 82.08\n",
            "\n",
            "Test set: Average loss: 0.539, Accuracy: 81.85\n",
            "\n",
            "Epoch 32 : \n",
            "Train set: Average loss: 0.6602, Accuracy: 82.37\n",
            "\n",
            "Test set: Average loss: 0.535, Accuracy: 81.94\n",
            "\n",
            "Epoch 33 : \n",
            "Train set: Average loss: 0.4054, Accuracy: 82.60\n",
            "\n",
            "Test set: Average loss: 0.548, Accuracy: 81.31\n",
            "\n",
            "Epoch 34 : \n",
            "Train set: Average loss: 0.3806, Accuracy: 82.38\n",
            "\n",
            "Test set: Average loss: 0.538, Accuracy: 82.22\n",
            "\n",
            "Epoch 35 : \n",
            "Train set: Average loss: 0.5177, Accuracy: 83.10\n",
            "\n",
            "Test set: Average loss: 0.520, Accuracy: 82.34\n",
            "\n",
            "Epoch 36 : \n",
            "Train set: Average loss: 0.4743, Accuracy: 83.35\n",
            "\n",
            "Test set: Average loss: 0.560, Accuracy: 80.98\n",
            "\n",
            "Epoch 37 : \n",
            "Train set: Average loss: 0.4155, Accuracy: 83.27\n",
            "\n",
            "Test set: Average loss: 0.551, Accuracy: 81.70\n",
            "\n",
            "Epoch 38 : \n",
            "Train set: Average loss: 0.5600, Accuracy: 83.43\n",
            "\n",
            "Test set: Average loss: 0.503, Accuracy: 83.00\n",
            "\n",
            "Epoch 39 : \n",
            "Train set: Average loss: 0.6416, Accuracy: 83.43\n",
            "\n",
            "Test set: Average loss: 0.515, Accuracy: 82.75\n",
            "\n",
            "Epoch 40 : \n",
            "Train set: Average loss: 0.5949, Accuracy: 83.83\n",
            "\n",
            "Test set: Average loss: 0.503, Accuracy: 82.89\n",
            "\n",
            "Epoch 41 : \n",
            "Train set: Average loss: 0.3367, Accuracy: 83.78\n",
            "\n",
            "Test set: Average loss: 0.520, Accuracy: 82.72\n",
            "\n",
            "Epoch 42 : \n",
            "Train set: Average loss: 0.5297, Accuracy: 84.02\n",
            "\n",
            "Test set: Average loss: 0.503, Accuracy: 83.29\n",
            "\n",
            "Epoch 43 : \n",
            "Train set: Average loss: 0.4356, Accuracy: 83.95\n",
            "\n",
            "Test set: Average loss: 0.517, Accuracy: 82.83\n",
            "\n",
            "Epoch 44 : \n",
            "Train set: Average loss: 0.4440, Accuracy: 84.28\n",
            "\n",
            "Test set: Average loss: 0.511, Accuracy: 83.13\n",
            "\n",
            "Epoch 45 : \n",
            "Train set: Average loss: 0.3922, Accuracy: 84.44\n",
            "\n",
            "Test set: Average loss: 0.528, Accuracy: 82.20\n",
            "\n",
            "Epoch 46 : \n",
            "Train set: Average loss: 0.4822, Accuracy: 84.10\n",
            "\n",
            "Test set: Average loss: 0.495, Accuracy: 83.28\n",
            "\n",
            "Epoch 47 : \n",
            "Train set: Average loss: 0.5645, Accuracy: 84.72\n",
            "\n",
            "Test set: Average loss: 0.502, Accuracy: 82.98\n",
            "\n",
            "Epoch 48 : \n",
            "Train set: Average loss: 0.4563, Accuracy: 84.82\n",
            "\n",
            "Test set: Average loss: 0.496, Accuracy: 83.36\n",
            "\n",
            "Epoch 49 : \n",
            "Train set: Average loss: 0.3465, Accuracy: 84.74\n",
            "\n",
            "Test set: Average loss: 0.482, Accuracy: 84.08\n",
            "\n",
            "Epoch 50 : \n",
            "Train set: Average loss: 0.3595, Accuracy: 84.98\n",
            "\n",
            "Test set: Average loss: 0.533, Accuracy: 82.32\n",
            "\n",
            "Epoch 51 : \n",
            "Train set: Average loss: 0.3879, Accuracy: 84.96\n",
            "\n",
            "Test set: Average loss: 0.488, Accuracy: 83.77\n",
            "\n",
            "Epoch 52 : \n",
            "Train set: Average loss: 0.3584, Accuracy: 85.16\n",
            "\n",
            "Test set: Average loss: 0.524, Accuracy: 82.67\n",
            "\n",
            "Epoch 53 : \n",
            "Train set: Average loss: 0.3535, Accuracy: 85.45\n",
            "\n",
            "Test set: Average loss: 0.496, Accuracy: 83.32\n",
            "\n",
            "Epoch 54 : \n",
            "Train set: Average loss: 0.5121, Accuracy: 85.36\n",
            "\n",
            "Test set: Average loss: 0.497, Accuracy: 83.63\n",
            "\n",
            "Epoch 55 : \n",
            "Train set: Average loss: 0.4236, Accuracy: 85.67\n",
            "\n",
            "Test set: Average loss: 0.473, Accuracy: 84.07\n",
            "\n",
            "Epoch 56 : \n",
            "Train set: Average loss: 0.6611, Accuracy: 85.53\n",
            "\n",
            "Test set: Average loss: 0.492, Accuracy: 83.79\n",
            "\n",
            "Epoch 57 : \n",
            "Train set: Average loss: 0.4086, Accuracy: 85.78\n",
            "\n",
            "Test set: Average loss: 0.495, Accuracy: 83.45\n",
            "\n",
            "Epoch 58 : \n",
            "Train set: Average loss: 0.4977, Accuracy: 85.89\n",
            "\n",
            "Test set: Average loss: 0.491, Accuracy: 83.67\n",
            "\n",
            "Epoch 59 : \n",
            "Train set: Average loss: 0.4799, Accuracy: 85.75\n",
            "\n",
            "Test set: Average loss: 0.490, Accuracy: 84.08\n",
            "\n",
            "Epoch 60 : \n",
            "Train set: Average loss: 0.4966, Accuracy: 86.06\n",
            "\n",
            "Test set: Average loss: 0.492, Accuracy: 83.56\n",
            "\n",
            "Epoch 61 : \n",
            "Train set: Average loss: 0.4286, Accuracy: 86.06\n",
            "\n",
            "Test set: Average loss: 0.480, Accuracy: 83.78\n",
            "\n",
            "Epoch 62 : \n",
            "Train set: Average loss: 0.3936, Accuracy: 86.08\n",
            "\n",
            "Test set: Average loss: 0.479, Accuracy: 84.37\n",
            "\n",
            "Epoch 63 : \n",
            "Train set: Average loss: 0.3600, Accuracy: 86.45\n",
            "\n",
            "Test set: Average loss: 0.499, Accuracy: 84.22\n",
            "\n",
            "Epoch 64 : \n",
            "Train set: Average loss: 0.2956, Accuracy: 86.56\n",
            "\n",
            "Test set: Average loss: 0.476, Accuracy: 84.31\n",
            "\n",
            "Epoch 65 : \n",
            "Train set: Average loss: 0.4825, Accuracy: 86.52\n",
            "\n",
            "Test set: Average loss: 0.475, Accuracy: 84.31\n",
            "\n",
            "Epoch 66 : \n",
            "Train set: Average loss: 0.5002, Accuracy: 86.65\n",
            "\n",
            "Test set: Average loss: 0.486, Accuracy: 84.24\n",
            "\n",
            "Epoch 67 : \n",
            "Train set: Average loss: 0.5781, Accuracy: 86.79\n",
            "\n",
            "Test set: Average loss: 0.471, Accuracy: 84.42\n",
            "\n",
            "Epoch 68 : \n",
            "Train set: Average loss: 0.2850, Accuracy: 86.51\n",
            "\n",
            "Test set: Average loss: 0.488, Accuracy: 83.97\n",
            "\n",
            "Epoch 69 : \n",
            "Train set: Average loss: 0.4170, Accuracy: 86.79\n",
            "\n",
            "Test set: Average loss: 0.480, Accuracy: 84.17\n",
            "\n",
            "Epoch 70 : \n",
            "Train set: Average loss: 0.4671, Accuracy: 86.82\n",
            "\n",
            "Test set: Average loss: 0.461, Accuracy: 84.81\n",
            "\n",
            "Epoch 71 : \n",
            "Train set: Average loss: 0.3682, Accuracy: 87.00\n",
            "\n",
            "Test set: Average loss: 0.472, Accuracy: 84.36\n",
            "\n",
            "Epoch 72 : \n",
            "Train set: Average loss: 0.2117, Accuracy: 86.89\n",
            "\n",
            "Test set: Average loss: 0.472, Accuracy: 84.41\n",
            "\n",
            "Epoch 73 : \n",
            "Train set: Average loss: 0.4155, Accuracy: 87.14\n",
            "\n",
            "Test set: Average loss: 0.484, Accuracy: 83.88\n",
            "\n",
            "Epoch 74 : \n",
            "Train set: Average loss: 0.6409, Accuracy: 87.12\n",
            "\n",
            "Test set: Average loss: 0.486, Accuracy: 84.66\n"
          ]
        }
      ]
    }
  ]
}